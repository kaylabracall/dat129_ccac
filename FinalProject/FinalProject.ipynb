{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Web Scraping\n",
    "Kayla Bracall\n",
    "DAT 129 - Python 2 - Spring 2020\n",
    "Final Project\n",
    "\n",
    "This program will scrape yarn.com to find different types of yarn and their prices. It will then rank the yarn by the average \n",
    "most expensive price. It will also output the most common yarn weight for sale. Finally, it will write the yarn dictionary\n",
    "to a csv file. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using urllib and BeautifulSoup, this project aims to scrape information from yarn.com to find out which yarn is on average, the most expensive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mtp\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "# getting html from search results at ravelery.com for both knitting and crochet patterns\n",
    "\n",
    "def get_search_url(term):\n",
    "    '''assembles a query against goodreads.com given a search term'''\n",
    "    url = \"https://www.yarn.com/search?&q=%s\" % (str(term))\n",
    "    return url\n",
    "\n",
    "def getPageText(url):\n",
    "    '''Given a URL, fetches the raw HTML''' \n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        return response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glance at yarn.com finds we can search for the below yarn types:\n",
    "* alpaca\n",
    "* bamboo\n",
    "* cashmere\n",
    "* cotton\n",
    "* luxury\n",
    "* polyester\n",
    "* silk\n",
    "* wool \n",
    "\n",
    "## Scrape for each different type of yarn below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The below code scrapes for polyester based yarns and returns the average price of those yarns'''\n",
    "pageText = getPageText(get_search_url('polyester'))\n",
    "'''Scrape for polyester yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "#print(soup)\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "poly_count = 0\n",
    "total_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try:\n",
    "        if price:\n",
    "            poly_count = poly_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            total_price = total_price + price_num # add each price together\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError: # account for code scraping an item that cannot be cast to float \n",
    "        continue \n",
    "\n",
    "poly_average_price = float(total_price)/poly_count        \n",
    "pretty_poly = round(poly_average_price, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageText = getPageText(get_search_url('wool'))\n",
    "'''Scrape for wool yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "wool_count = 0\n",
    "tot_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try:\n",
    "        if price:\n",
    "            wool_count = wool_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            tot_price = tot_price + price_num\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError: # account for code scraping an item that cannot be cast to float \n",
    "        continue\n",
    "\n",
    "wool_average_price = float(tot_price)/wool_count\n",
    "pretty_wool = round(wool_average_price, 2) # round to two decimal points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageText = getPageText(get_search_url('silk'))\n",
    "'''Scrape for silk yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "silk_count = 0\n",
    "tot_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try:\n",
    "        if price:\n",
    "            silk_count = silk_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            tot_price = tot_price + price_num\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "silk_average_price = float(tot_price)/silk_count\n",
    "pretty_silk = round(silk_average_price, 2) # round to two decimal points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageText = getPageText(get_search_url('alpaca'))\n",
    "'''Scrape for alpaca yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "alpaca_count = 0\n",
    "tot_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try:\n",
    "        if price:\n",
    "            alpaca_count = alpaca_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            tot_price = tot_price + price_num\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError: # account for code scraping an item that cannot be cast to float \n",
    "        continue\n",
    "\n",
    "alpaca_average_price = float(tot_price)/alpaca_count\n",
    "pretty_alpaca = round(alpaca_average_price, 2) # round to two decimal points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageText = getPageText(get_search_url('bamboo'))\n",
    "'''Scrape for bamboo yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "#print(soup)\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "bamboo_count = 0\n",
    "total_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try:\n",
    "        if price:\n",
    "            bamboo_count = bamboo_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            total_price = total_price + price_num\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError: # account for code scraping an item that cannot be cast to float \n",
    "        continue \n",
    "\n",
    "bamboo_average_price = float(total_price)/bamboo_count        \n",
    "pretty_bamboo = round(bamboo_average_price, 2) # round to two decimal points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageText = getPageText(get_search_url('cashmere'))\n",
    "'''Scrape for cahsmere yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "#print(soup)\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "cash_count = 0\n",
    "total_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try:\n",
    "        if price:\n",
    "            cash_count = cash_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            total_price = total_price + price_num\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError: # account for code scraping an item that cannot be cast to float \n",
    "        continue \n",
    "cash_average_price = float(total_price)/cash_count        \n",
    "pretty_cash = round(cash_average_price, 2) # round to two decimal points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageText = getPageText(get_search_url('luxury'))\n",
    "'''Scrape for luxury yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "#print(soup)\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "lux_count = 0\n",
    "total_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try: \n",
    "        if price:\n",
    "            lux_count = lux_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            total_price = total_price + price_num\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError: # account for code scraping an item that cannot be cast to float \n",
    "        continue \n",
    "lux_average_price = float(total_price)/lux_count        \n",
    "pretty_lux = round(lux_average_price, 2)# round to two decimal points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageText = getPageText(get_search_url('cotton'))\n",
    "'''Scrape for cotton yarn'''\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "s = soup.find_all('div','product-prices__price')\n",
    "cotton_count = 0\n",
    "total_price = 0\n",
    "\n",
    "for item in s:\n",
    "    price = item.find('span', None)\n",
    "    try:\n",
    "        if price:\n",
    "            cotton_count = cotton_count +1 # increase counter\n",
    "            price_variable = price.text\n",
    "            price_num = float(price_variable.replace('$','')) # cast to float and replace the $ with an empty string\n",
    "            total_price = total_price + price_num\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError: # account for code scraping an item that cannot be cast to float \n",
    "        continue \n",
    "cotton_average_price = float(total_price)/cotton_count        \n",
    "pretty_cotton = round(cotton_average_price, 2) # round to two decimal points "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, find the most common weight.\n",
    "\n",
    "The different yarn weights are:\n",
    "* lace\n",
    "* fingering\n",
    "* sock \n",
    "* sport\n",
    "* dk\n",
    "* worsted\n",
    "* bulky\n",
    "* super bulky\n",
    "\n",
    "Scrape for the weights below and add to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This code scrapes yarn.com for yarn types, counts each type, then adds the type to the dictionary'''\n",
    "pageText = getPageText(get_search_url('yds'))\n",
    "soup = BeautifulSoup(pageText, 'html.parser')\n",
    "s = soup.find_all('div','product-summary__attributes')\n",
    "\n",
    "# initialize counters\n",
    "lace_count = 0\n",
    "fingering_count = 0 \n",
    "sock_count = 0\n",
    "sport_count = 0\n",
    "dk_count = 0\n",
    "worsted_count = 0\n",
    "bulky_count = 0 \n",
    "superbulky_count = 0\n",
    "\n",
    "# add up counts\n",
    "for item in s:\n",
    "    weight = item.find('div', None)\n",
    "    if weight:\n",
    "        weight_var = weight.text\n",
    "        if weight_var == \"Lace\":\n",
    "            lace_count = lace_count + 1 \n",
    "        elif weight_var == \"Fingering\":\n",
    "            fingering_count = fingering_count + 1\n",
    "        elif weight_var == \"Sock\":\n",
    "            sock_count = sock_count + 1\n",
    "        elif weight_var == \"Sport\":\n",
    "            sport_count = sport_count + 1 \n",
    "        elif weight_var == \"DK\":\n",
    "            dk_count = dk_count + 1 \n",
    "        elif weight_var == \"Worsted\":\n",
    "            worsted_count = worsted_count + 1\n",
    "        elif weight_var == \"Bulky\":\n",
    "            bulky_count = bulky_count + 1\n",
    "        elif weight_var == \"Super Bulky\":\n",
    "            superbulky_count = superbulky_count + 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# put counts in dictionary         \n",
    "weight_dict = {'Lace': lace_count,'Fingering': fingering_count, 'Sock': sock_count, 'sport': sport_count, 'DK': dk_count, \n",
    "              'Worsted': worsted_count, 'Bulky': bulky_count, 'Super Bulky': superbulky_count}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function that will \"sort\" dictionaries so that the largest value is first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section of code taken from Python 1 final \n",
    "\n",
    "def sort_key_list(word_dictionary):\n",
    "    '''This function takes a dictionary and moves the values to a list. From \n",
    "    there, it sorts the value list and compares it to the keys in the dictionary. \n",
    "    If the item in the list equals the key, it adds it to a new list. The \n",
    "    function returns the sorted list'''\n",
    "    # intialize lists\n",
    "    sorted_key_list = []\n",
    "    value_list = []\n",
    "    for value in word_dictionary:\n",
    "        temp = word_dictionary[value] # pull out value\n",
    "        value_list.append(temp) # add value to empty list\n",
    "    # sort list\n",
    "    value_list.sort()\n",
    "    # sort list in descending order\n",
    "    value_list_sort = value_list[::-1]\n",
    "\n",
    "    for item in value_list_sort:\n",
    "        for key in word_dictionary:\n",
    "            # if key equals item in list and item is not already in sorted_key_list, add it to list\n",
    "            if word_dictionary[key] == item and key not in sorted_key_list:\n",
    "                sorted_key_list.append(key)\n",
    "    return sorted_key_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within main, create yarn dictionary, then sort weight and yarn dictionaries. Return first value in each dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    yarn_dict = {'silk': pretty_silk, 'wool': pretty_wool, 'bamboo': pretty_bamboo, 'polyester': pretty_poly, 'cashmere': pretty_cash,\n",
    "            'luxury':pretty_lux, 'cotton': pretty_cotton, 'alpaca': pretty_alpaca}\n",
    "    \n",
    "    sorted_weight_dict = sort_key_list(weight_dict) # sort the weight dictionary to find most common weight of yarn\n",
    "    sorted_yarn_dict = sort_key_list(yarn_dict) # sort yarn dictionary to find most expensive yarn on average\n",
    "    print(\"On average, which yarn is more expensive?\")\n",
    "    print('')\n",
    "    print(\"Average price of silk yarn: $\", pretty_silk)\n",
    "    print(\"Average price of wool yarn: $\", pretty_wool)\n",
    "    print('Average price of polyester yarn: $', pretty_poly)\n",
    "    print('Average price of bamboo yarn: $', pretty_bamboo)\n",
    "    print('Average price of cashmere yarn: $', pretty_cash)\n",
    "    print('Average price of cotton yarn: $', pretty_cotton)\n",
    "    print('Average price of luxury yarn: $', pretty_lux)\n",
    "    print('Average price of alpaca yarn: $', pretty_alpaca)\n",
    "    print('')\n",
    "\n",
    "    print('Which yarn is most expensive?')\n",
    "    print(sorted_yarn_dict[0], 'yarn')\n",
    "    print('')\n",
    "    print(\"Which weight of yarn is most common?\")\n",
    "    print(sorted_weight_dict[0], 'weight')\n",
    "    \n",
    "    #for item in sorted_weight_dict:\n",
    "     #   print(item, ':',weight_dict[item], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, which yarn is more expensive?\n",
      "\n",
      "Average price of silk yarn: $ 8.06\n",
      "Average price of wool yarn: $ 9.0\n",
      "Average price of polyester yarn: $ 7.8\n",
      "Average price of bamboo yarn: $ 10.89\n",
      "Average price of cashmere yarn: $ 12.51\n",
      "Average price of cotton yarn: $ 9.21\n",
      "Average price of luxury yarn: $ 12.08\n",
      "Average price of alpaca yarn: $ 8.66\n",
      "\n",
      "Which yarn is most expensive?\n",
      "cashmere yarn\n",
      "\n",
      "Which weight of yarn is most common?\n",
      "DK weight\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write yarn dictionary to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'yarndict.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-b167804f9c27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m'''Write yarn dictionary to csv file'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yarndict.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mfnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'silk'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wool'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'polyester'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bamboo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cashmere'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cotton'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'luxury'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alpaca'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# define header names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'yarndict.csv'"
     ]
    }
   ],
   "source": [
    "yarn_dict = {'silk': pretty_silk, 'wool': pretty_wool, 'bamboo': pretty_bamboo, 'polyester': pretty_poly, 'cashmere': pretty_cash,\n",
    "            'luxury':pretty_lux, 'cotton': pretty_cotton, 'alpaca': pretty_alpaca}\n",
    "\n",
    "'''Write yarn dictionary to csv file'''\n",
    "with open('yarndict.csv', 'w') as y:\n",
    "    fnames = ['silk', 'wool', 'polyester', 'bamboo', 'cashmere', 'cotton', 'luxury', 'alpaca'] # define header names\n",
    "    writer = csv.DictWriter(y, fieldnames= fnames) \n",
    "    writer.writeheader() # write header row\n",
    "    writer.writerow(yarn_dict) # pull in yarn dictionary for row. Keys should match header names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
